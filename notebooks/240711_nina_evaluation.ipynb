{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from src.evaluation.metrics import aggregate_scores, calculate_scores\n",
    "from src.data.data_loading import load_config\n",
    "from src.data.code_processor import parse_code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\merti\\\\PycharmProjects\\\\cadenza-playwright-llm'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set working directory to project root - EXECUTE ONLY ONCE or RESTART KERNEL\n",
    "os.chdir('..')\n",
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "config = load_config(config_path='config/config.yaml')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scoring\n",
    "Metrics implemented and used in this project (see `src/evaluation/metrics.py`):\n",
    "* **Weighted BLEU** $ \\in [0.0, 1.0] $: The BLEU score proposed by [Papineni et al. (2002)](https://aclanthology.org/P02-1040.pdf) [1], [2] is a metric that measures the similarity between two sequences of text. The weighted BLEU score is a variant implementd in this project that uses a weighted average of the BLEU scores of the precondition part and the actual generated additional part in teh generated test script. The weights are defined in the configuration file `config/config.yaml`.\n",
    "* **Success Rate** $ \\in [0.0, 1.0] $: The success rate is the proportion of generated test scripts that run successfully, no matter if they are semantically correct or not.\n",
    "* **Levenshtein Distance** $ d(s, t) \\in \\mathbb{N} $: The Levenshtein distance between strings $ s $ and $ t $ is an integer that measures the minimum number of single-character edits (insertions, deletions, or substitutions) required to change $ s $ into $ t $."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-14 11:27:22 [\u001B[34msrc.data.code_processor:15\u001B[0m] [DEBUG\u001B[0m] >>>> Code parsed successfully. - Lines of Code: 16\u001B[0m\n",
      "2024-07-14 11:27:22 [\u001B[34msrc.data.code_processor:15\u001B[0m] [DEBUG\u001B[0m] >>>> Code parsed successfully. - Lines of Code: 31\u001B[0m\n",
      "2024-07-14 11:27:22 [\u001B[34msrc.data.code_processor:15\u001B[0m] [DEBUG\u001B[0m] >>>> Code parsed successfully. - Lines of Code: 32\u001B[0m\n",
      "2024-07-14 11:27:22 [\u001B[34msrc.data.code_processor:15\u001B[0m] [DEBUG\u001B[0m] >>>> Code parsed successfully. - Lines of Code: 12\u001B[0m\n",
      "2024-07-14 11:27:22 [\u001B[34msrc.data.code_processor:15\u001B[0m] [DEBUG\u001B[0m] >>>> Code parsed successfully. - Lines of Code: 13\u001B[0m\n",
      "2024-07-14 11:27:22 [\u001B[34msrc.data.code_processor:15\u001B[0m] [DEBUG\u001B[0m] >>>> Code parsed successfully. - Lines of Code: 13\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# Define example test cases\n",
    "test_cases = [\n",
    "    {\n",
    "        'generated_code': parse_code(config['paths']['prediction_dir']+'/1_2.pred.ts'),\n",
    "        'validation_code': parse_code(config['dataloading']['test_script_dir']+'/1_2.spec.ts'),\n",
    "        'precondition_code': parse_code(config['dataloading']['test_script_dir']+'/1_1.spec.ts')\n",
    "    },\n",
    "    {\n",
    "        'generated_code': parse_code(config['paths']['prediction_dir']+'/2_2.pred.ts'),\n",
    "        'validation_code': parse_code(config['dataloading']['test_script_dir']+'/2_2.spec.ts'),\n",
    "        'precondition_code': parse_code(config['dataloading']['test_script_dir']+'/2_1.spec.ts')\n",
    "    }\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{'weighted bleu': [0.4912019643332622],\n 'success rate': [None],\n 'levenshtein distance': [0.33620689655172414]}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run for one test case\n",
    "scores = calculate_scores([test_cases[0]])\n",
    "scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'weighted bleu': [0.4912019643332622, 0.3995064945165301],\n 'success rate': [None, None],\n 'levenshtein distance': [0.33620689655172414, 0.2632398753894081]}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run for all test cases\n",
    "scores = calculate_scores(test_cases)\n",
    "scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-14 11:27:22 [\u001B[34msrc.evaluation.metrics:31\u001B[0m] [\u001B[33mWARNING\u001B[0m] >>>> Missing success rate scores. Skipping...\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'weighted bleu': 0.4453542294248961,\n 'success rate': None,\n 'levenshtein distance': 0.29972338597056614}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate scores\n",
    "agg_scores = aggregate_scores(scores)\n",
    "agg_scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-14 11:27:24 [\u001B[34m__main__:21\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Calculating scores...\u001B[0m\n",
      "2024-07-14 11:27:24 [\u001B[34msrc.data.code_processor:15\u001B[0m] [DEBUG\u001B[0m] >>>> Code parsed successfully. - Lines of Code: 16\u001B[0m\n",
      "2024-07-14 11:27:24 [\u001B[34msrc.data.code_processor:15\u001B[0m] [DEBUG\u001B[0m] >>>> Code parsed successfully. - Lines of Code: 31\u001B[0m\n",
      "2024-07-14 11:27:24 [\u001B[34msrc.data.code_processor:15\u001B[0m] [DEBUG\u001B[0m] >>>> Code parsed successfully. - Lines of Code: 32\u001B[0m\n",
      "2024-07-14 11:27:24 [\u001B[34msrc.data.code_processor:15\u001B[0m] [DEBUG\u001B[0m] >>>> Code parsed successfully. - Lines of Code: 12\u001B[0m\n",
      "2024-07-14 11:27:24 [\u001B[34msrc.data.code_processor:15\u001B[0m] [DEBUG\u001B[0m] >>>> Code parsed successfully. - Lines of Code: 13\u001B[0m\n",
      "2024-07-14 11:27:24 [\u001B[34msrc.data.code_processor:15\u001B[0m] [DEBUG\u001B[0m] >>>> Code parsed successfully. - Lines of Code: 13\u001B[0m\n",
      "2024-07-14 11:27:24 [\u001B[34m__main__:40\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Scores calculated. Aggregating...\u001B[0m\n",
      "2024-07-14 11:27:24 [\u001B[34msrc.evaluation.metrics:31\u001B[0m] [\u001B[33mWARNING\u001B[0m] >>>> Missing success rate scores. Skipping...\u001B[0m\n",
      "2024-07-14 11:27:24 [\u001B[34m__main__:42\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Aggregated scores: {'weighted bleu': 0.4453542294248961, 'success rate': None, 'levenshtein distance': 0.29972338597056614}\u001B[0m\n",
      "2024-07-14 11:27:24 [\u001B[34m__main__:55\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Results saved to ./data/scores//eval_scores_20240714-1127.pkl\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# Run complete evaluation script\n",
    "!python scripts/evaluation.py --config=config/config.yaml"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "  file_id test_case test_step  weighted bleu success rate  \\\n0     1_2         1         2       0.445354         None   \n1     2_2         2         2       0.445354         None   \n\n   levenshtein distance  \n0              0.299723  \n1              0.299723  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_id</th>\n      <th>test_case</th>\n      <th>test_step</th>\n      <th>weighted bleu</th>\n      <th>success rate</th>\n      <th>levenshtein distance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1_2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.445354</td>\n      <td>None</td>\n      <td>0.299723</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2_2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.445354</td>\n      <td>None</td>\n      <td>0.299723</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load evaluation results\n",
    "results = pd.read_pickle(config['paths']['scores_dir']+'eval_scores_20240714-1123.pkl')\n",
    "results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# References\n",
    "[1]\n",
    "```bibtex\n",
    "@INPROCEEDINGS{Papineni02bleu:a,\n",
    "    author = {Kishore Papineni and Salim Roukos and Todd Ward and Wei-jing Zhu},\n",
    "    title = {BLEU: a Method for Automatic Evaluation of Machine Translation},\n",
    "    booktitle = {},\n",
    "    year = {2002},\n",
    "    pages = {311--318}\n",
    "}\n",
    "```\n",
    "[2]\n",
    "```bibtex\n",
    "@inproceedings{lin-och-2004-orange,\n",
    "    title = \"{ORANGE}: a Method for Evaluating Automatic Evaluation Metrics for Machine Translation\",\n",
    "    author = \"Lin, Chin-Yew  and\n",
    "      Och, Franz Josef\",\n",
    "    booktitle = \"{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics\",\n",
    "    month = \"aug 23{--}aug 27\",\n",
    "    year = \"2004\",\n",
    "    address = \"Geneva, Switzerland\",\n",
    "    publisher = \"COLING\",\n",
    "    url = \"https://www.aclweb.org/anthology/C04-1072\",\n",
    "    pages = \"501--507\",\n",
    "}\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
