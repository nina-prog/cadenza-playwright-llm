{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from src.evaluation.metrics import aggregate_scores, calculate_scores\n",
    "from src.data.data_loading import load_config\n",
    "from src.data.code_processor import parse_code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\merti\\\\PycharmProjects\\\\cadenza-playwright-llm'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set working directory to project root - EXECUTE ONLY ONCE or RESTART KERNEL\n",
    "os.chdir('..')\n",
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "config = load_config(config_path='config/config.yaml')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scoring\n",
    "Metrics implemented and used in this project (see `src/evaluation/metrics.py`):\n",
    "* **Weighted BLEU** $ \\in [0.0, 1.0] $: The BLEU score proposed by [Papineni et al. (2002)](https://aclanthology.org/P02-1040.pdf) [1], [2] is a metric that measures the similarity between two sequences of text. The weighted BLEU score is a variant implementd in this project that uses a weighted average of the BLEU scores of the precondition part and the actual generated additional part in teh generated test script. The weights are defined in the configuration file `config/config.yaml`.\n",
    "* **Success Rate** $ \\in [0.0, 1.0] $: The success rate is the proportion of generated test scripts that run successfully, no matter if they are semantically correct or not.\n",
    "* **Levenshtein Distance** $ d(s, t) \\in \\mathbb{N} $: The Levenshtein distance between strings $ s $ and $ t $ is an integer that measures the minimum number of single-character edits (insertions, deletions, or substitutions) required to change $ s $ into $ t $."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-11 19:25:36 [\u001B[34msrc.data.code_processor:15\u001B[0m] [DEBUG\u001B[0m] >>>> Code parsed successfully. - Lines of Code: 16\u001B[0m\n",
      "2024-07-11 19:25:36 [\u001B[34msrc.data.code_processor:15\u001B[0m] [DEBUG\u001B[0m] >>>> Code parsed successfully. - Lines of Code: 31\u001B[0m\n",
      "2024-07-11 19:25:36 [\u001B[34msrc.data.code_processor:15\u001B[0m] [DEBUG\u001B[0m] >>>> Code parsed successfully. - Lines of Code: 32\u001B[0m\n",
      "2024-07-11 19:25:36 [\u001B[34msrc.data.code_processor:15\u001B[0m] [DEBUG\u001B[0m] >>>> Code parsed successfully. - Lines of Code: 12\u001B[0m\n",
      "2024-07-11 19:25:36 [\u001B[34msrc.data.code_processor:15\u001B[0m] [DEBUG\u001B[0m] >>>> Code parsed successfully. - Lines of Code: 13\u001B[0m\n",
      "2024-07-11 19:25:36 [\u001B[34msrc.data.code_processor:15\u001B[0m] [DEBUG\u001B[0m] >>>> Code parsed successfully. - Lines of Code: 13\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# Define example test cases\n",
    "test_cases = [\n",
    "    {\n",
    "        'generated_code': parse_code(config['paths']['prediction_dir']+'/1_2.pred.ts'),\n",
    "        'validation_code': parse_code(config['dataloading']['test_script_dir']+'/1_2.spec.ts'),\n",
    "        'precondition_code': parse_code(config['dataloading']['test_script_dir']+'/1_1.spec.ts')\n",
    "    },\n",
    "    {\n",
    "        'generated_code': parse_code(config['paths']['prediction_dir']+'/2_2.pred.ts'),\n",
    "        'validation_code': parse_code(config['dataloading']['test_script_dir']+'/2_2.spec.ts'),\n",
    "        'precondition_code': parse_code(config['dataloading']['test_script_dir']+'/2_1.spec.ts')\n",
    "    }\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T17:25:36.724352900Z",
     "start_time": "2024-07-11T17:25:36.625692100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "{'weighted bleu': [0.4912019643332622],\n 'success rate': [None],\n 'levenshtein distance': [0.33620689655172414]}"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run for one test case\n",
    "scores = calculate_scores([test_cases[0]])\n",
    "scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T17:25:38.639930500Z",
     "start_time": "2024-07-11T17:25:38.557127500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "{'weighted bleu': [0.4912019643332622, 0.3995064945165301],\n 'success rate': [None, None],\n 'levenshtein distance': [0.33620689655172414, 0.2632398753894081]}"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run for all test cases\n",
    "scores = calculate_scores(test_cases)\n",
    "scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T17:25:40.221612300Z",
     "start_time": "2024-07-11T17:25:40.106365500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-11 19:39:09 [\u001B[34msrc.evaluation.metrics:31\u001B[0m] [\u001B[33mWARNING\u001B[0m] >>>> Missing success rate scores. Skipping...\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'weighted bleu': 0.4453542294248961,\n 'success rate': None,\n 'levenshtein distance': 0.29972338597056614}"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate scores\n",
    "agg_scores = aggregate_scores(scores)\n",
    "agg_scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T17:39:10.045878900Z",
     "start_time": "2024-07-11T17:39:09.899033600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run evaluation script"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# References\n",
    "[1]\n",
    "```bibtex\n",
    "@INPROCEEDINGS{Papineni02bleu:a,\n",
    "    author = {Kishore Papineni and Salim Roukos and Todd Ward and Wei-jing Zhu},\n",
    "    title = {BLEU: a Method for Automatic Evaluation of Machine Translation},\n",
    "    booktitle = {},\n",
    "    year = {2002},\n",
    "    pages = {311--318}\n",
    "}\n",
    "```\n",
    "[2]\n",
    "```bibtex\n",
    "@inproceedings{lin-och-2004-orange,\n",
    "    title = \"{ORANGE}: a Method for Evaluating Automatic Evaluation Metrics for Machine Translation\",\n",
    "    author = \"Lin, Chin-Yew  and\n",
    "      Och, Franz Josef\",\n",
    "    booktitle = \"{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics\",\n",
    "    month = \"aug 23{--}aug 27\",\n",
    "    year = \"2004\",\n",
    "    address = \"Geneva, Switzerland\",\n",
    "    publisher = \"COLING\",\n",
    "    url = \"https://www.aclweb.org/anthology/C04-1072\",\n",
    "    pages = \"501--507\",\n",
    "}\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
