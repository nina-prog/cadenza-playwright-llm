{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test Generation"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Selection of model\n",
    "\n",
    "The originally used model llava-hf/llava-1.5-7b-hf cannot be finetuned with the code base https://github.com/haotian-liu/LLaVA, as the pre-trained weights are not adopted. We have also not found any other code base explicitly for the model.\n",
    "\n",
    "We first tested the model liuhaotian/llava-v1.6-vicuna-7b and liuhaotian/llava-v1.6-mistral-7b but encountered errors for which we found nothing on the net.\n",
    "\n",
    "Finally, we used the liuhaotian/llava-v1.5-7b model, where we had to fix many bugs. In the chapter “Bash scripts” one of the biggest bugs is discussed.\n",
    "\n",
    "One problem with the new model is that it reacts differently to the prompts, which is why other prompt templates were tested again."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Changes to general database\n",
    "\n",
    "TODO"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### General prompt structure\n",
    "\n",
    "The prompt is divided into 4 sections:\n",
    "-\tSimplified HTML Content: This section contains a list of the extracted HTML elements.\n",
    "-\tPlaywright Test Precondition: This section contains the code that must be executed to get to the point from which the current step has to be executed.\n",
    "-\tUI Test Description: This section contains the test description for the current step, which comes from the user.\n",
    "-\tScreenshot: This section contains the image.\n",
    "-\tTask: The task for the LLM is described in this section. There are various templates for this section.\n",
    "\n",
    "In the following, the input prompt with Template_1 is given for 01_01.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T13:37:32.518097Z",
     "start_time": "2024-07-20T13:37:32.507332Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"### Simplified HTML Content: Buttons: {\\\"id\\\": \\\"navigationTrigger\\\", \\\"class\\\": \\\"button button-icon button-borderless\\\"} {\\\"id\\\": \\\"workbook-create\\\", \\\"class\\\": \\\"button workbook-create button-icon\\\"} {\\\"id\\\": \\\"RDxYr2vFytOijWjelj7P1\\\", \\\"class\\\": \\\"button navigation-menu button-icon\\\"} {\\\"text\\\": \\\"Arbeitsmappe importieren\\\", \\\"class\\\": \\\"button\\\"} {\\\"text\\\": \\\"Repository neu einlesen …\\\", \\\"class\\\": \\\"button\\\"} Inputs: {\\\"class\\\": \\\"select2-search__field\\\", \\\"aria-label\\\": \\\"Suchen nach …\\\", \\\"type\\\": \\\"search\\\", \\\"placeholder\\\": \\\"Suchen nach …\\\"} Links: {\\\"text\\\": \\\"Zum Navigatorbaum springen\\\", \\\"id\\\": \\\"skip-to-navigator\\\", \\\"class\\\": \\\"button button-primary\\\"} {\\\"text\\\": \\\"Zum Hauptbereich springen\\\", \\\"id\\\": \\\"skip-to-content\\\", \\\"class\\\": \\\"button button-primary\\\"} {\\\"text\\\": \\\"Startseite\\\", \\\"id\\\": \\\"home\\\", \\\"class\\\": \\\"button button-icon button-borderless\\\"} {\\\"text\\\": \\\"Karte\\\"} {\\\"text\\\": \\\"Verzeichnis Tutorial\\\", \\\"id\\\": \\\"d-nav-tree-node_ROOT-Tutorial_firstContent\\\", \\\"class\\\": \\\"d-nav-tree-node--main d-hover-context\\\"} {\\\"text\\\": \\\"Verzeichnis Gewässergüte\\\", \\\"id\\\": \\\"d-nav-tree-node_ROOT-Gewässergüte_firstContent\\\", \\\"class\\\": \\\"d-nav-tree-node--main d-hover-context\\\"} {\\\"text\\\": \\\"Verzeichnis Automobile\\\", \\\"id\\\": \\\"d-nav-tree-node_ROOT-Automobile_firstContent\\\", \\\"class\\\": \\\"d-nav-tree-node--main d-hover-context\\\"} {\\\"text\\\": \\\"Verzeichnis Ergänzende Geodaten\\\", \\\"class\\\": \\\"d-nav-tree-node--main d-hover-context\\\"} {\\\"text\\\": \\\"Verzeichnis Zentrale Dienste\\\", \\\"id\\\": \\\"d-nav-tree-node_ROOT-Zentrale-Dienste_firstContent\\\", \\\"class\\\": \\\"d-nav-tree-node--main d-hover-context\\\"} {\\\"text\\\": \\\"Verzeichnis Meine Arbeitsmappen\\\", \\\"class\\\": \\\"d-nav-tree-node--main d-hover-context\\\"} {\\\"text\\\": \\\"Arbeitsmappe Zugangsdaten\\\", \\\"class\\\": \\\"d-nav-tree-node--main d-hover-context\\\"} {\\\"text\\\": \\\"Zugangsdaten\\\", \\\"class\\\": \\\"d-nav-tree-node--text ellipsis\\\"} {\\\"text\\\": \\\"disy Cadenza\\\"} {\\\"text\\\": \\\"Tutorials\\\"} {\\\"text\\\": \\\"Lernmodulen\\\"} {\\\"text\\\": \\\"Onlinehilfe\\\"} {\\\"text\\\": \\\"Webseite\\\"} {\\\"text\\\": \\\"Lernmodulen\\\"} {\\\"text\\\": \\\"1\\\", \\\"class\\\": \\\"startpage-section-navigation-item\\\"} {\\\"text\\\": \\\"2\\\", \\\"class\\\": \\\"startpage-section-navigation-item\\\"} {\\\"text\\\": \\\"3\\\", \\\"class\\\": \\\"startpage-section-navigation-item\\\"} {\\\"text\\\": \\\"4\\\", \\\"class\\\": \\\"startpage-section-navigation-item\\\"} {\\\"text\\\": \\\"5\\\", \\\"class\\\": \\\"startpage-section-navigation-item\\\"} {\\\"text\\\": \\\"6\\\", \\\"class\\\": \\\"startpage-section-navigation-item\\\"} {\\\"text\\\": \\\"7\\\", \\\"class\\\": \\\"startpage-section-navigation-item\\\"} {\\\"text\\\": \\\"disy Cadenza v9.4.71\\\", \\\"class\\\": \\\"userSpecificLink ellipsis hidden-xs\\\"} {\\\"text\\\": \\\"© Disy Informationssysteme GmbH\\\", \\\"class\\\": \\\"userSpecificLink ellipsis hidden-xs\\\"} {\\\"text\\\": \\\"Über Disy\\\", \\\"class\\\": \\\"userSpecificLink ellipsis\\\"} \\n\\n### Playwright Test Precondition: import { test, expect } from '@playwright/test'; import { writeFileSync } from 'fs'; test('test', async ({ page }) => { await page.goto('http://localhost:8080/cadenza/'); await page.getByRole('link', { name: 'Anmelden' }).click(); await page.getByLabel('Benutzername *').click(); await page.getByLabel('Benutzername *').fill('Admin'); await page.getByLabel('Benutzername *').press('Tab'); await page.getByPlaceholder(' ').fill('Admin'); await page.getByRole('button', { name: 'Anmelden' }).click(); }); \\n\\n### UI Test Description: Öffne die Arbeitsmappe \\\"Übersicht Messstellen\\\" im Ordner \\\"Gewässergüte\\\". \\n\\n### Screenshot: <image> \\n\\n### Task: You are a test automation script writer. I will describe a UI test in German and you will generate Playwright test code for the given webpage. Strictly follow these instructions: 1. Don't explain the code, just generate the code block itself. 2. You get some HTML elements and its attributes from the website. You can use playwright locators to find the elements by their attributes. 3. Use the precondition code to set up the initial state. You must continue the code. 4. Follow the steps in the ui test description to perform actions on the website. 5. Use the screenshot to understand the context of the test. Assistant:\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Simplified HTML Content: Buttons: {\"id\": \"navigationTrigger\", \"class\": \"button button-icon button-borderless\"} {\"id\": \"workbook-create\", \"class\": \"button workbook-create button-icon\"} {\"id\": \"RDxYr2vFytOijWjelj7P1\", \"class\": \"button navigation-menu button-icon\"} {\"text\": \"Arbeitsmappe importieren\", \"class\": \"button\"} {\"text\": \"Repository neu einlesen …\", \"class\": \"button\"} Inputs: {\"class\": \"select2-search__field\", \"aria-label\": \"Suchen nach …\", \"type\": \"search\", \"placeholder\": \"Suchen nach …\"} Links: {\"text\": \"Zum Navigatorbaum springen\", \"id\": \"skip-to-navigator\", \"class\": \"button button-primary\"} {\"text\": \"Zum Hauptbereich springen\", \"id\": \"skip-to-content\", \"class\": \"button button-primary\"} {\"text\": \"Startseite\", \"id\": \"home\", \"class\": \"button button-icon button-borderless\"} {\"text\": \"Karte\"} {\"text\": \"Verzeichnis Tutorial\", \"id\": \"d-nav-tree-node_ROOT-Tutorial_firstContent\", \"class\": \"d-nav-tree-node--main d-hover-context\"} {\"text\": \"Verzeichnis Gewässergüte\", \"id\": \"d-nav-tree-node_ROOT-Gewässergüte_firstContent\", \"class\": \"d-nav-tree-node--main d-hover-context\"} {\"text\": \"Verzeichnis Automobile\", \"id\": \"d-nav-tree-node_ROOT-Automobile_firstContent\", \"class\": \"d-nav-tree-node--main d-hover-context\"} {\"text\": \"Verzeichnis Ergänzende Geodaten\", \"class\": \"d-nav-tree-node--main d-hover-context\"} {\"text\": \"Verzeichnis Zentrale Dienste\", \"id\": \"d-nav-tree-node_ROOT-Zentrale-Dienste_firstContent\", \"class\": \"d-nav-tree-node--main d-hover-context\"} {\"text\": \"Verzeichnis Meine Arbeitsmappen\", \"class\": \"d-nav-tree-node--main d-hover-context\"} {\"text\": \"Arbeitsmappe Zugangsdaten\", \"class\": \"d-nav-tree-node--main d-hover-context\"} {\"text\": \"Zugangsdaten\", \"class\": \"d-nav-tree-node--text ellipsis\"} {\"text\": \"disy Cadenza\"} {\"text\": \"Tutorials\"} {\"text\": \"Lernmodulen\"} {\"text\": \"Onlinehilfe\"} {\"text\": \"Webseite\"} {\"text\": \"Lernmodulen\"} {\"text\": \"1\", \"class\": \"startpage-section-navigation-item\"} {\"text\": \"2\", \"class\": \"startpage-section-navigation-item\"} {\"text\": \"3\", \"class\": \"startpage-section-navigation-item\"} {\"text\": \"4\", \"class\": \"startpage-section-navigation-item\"} {\"text\": \"5\", \"class\": \"startpage-section-navigation-item\"} {\"text\": \"6\", \"class\": \"startpage-section-navigation-item\"} {\"text\": \"7\", \"class\": \"startpage-section-navigation-item\"} {\"text\": \"disy Cadenza v9.4.71\", \"class\": \"userSpecificLink ellipsis hidden-xs\"} {\"text\": \"© Disy Informationssysteme GmbH\", \"class\": \"userSpecificLink ellipsis hidden-xs\"} {\"text\": \"Über Disy\", \"class\": \"userSpecificLink ellipsis\"} \n",
      "\n",
      "### Playwright Test Precondition: import { test, expect } from '@playwright/test'; import { writeFileSync } from 'fs'; test('test', async ({ page }) => { await page.goto('http://localhost:8080/cadenza/'); await page.getByRole('link', { name: 'Anmelden' }).click(); await page.getByLabel('Benutzername *').click(); await page.getByLabel('Benutzername *').fill('Admin'); await page.getByLabel('Benutzername *').press('Tab'); await page.getByPlaceholder(' ').fill('Admin'); await page.getByRole('button', { name: 'Anmelden' }).click(); }); \n",
      "\n",
      "### UI Test Description: Öffne die Arbeitsmappe \"Übersicht Messstellen\" im Ordner \"Gewässergüte\". \n",
      "\n",
      "### Screenshot: <image> \n",
      "\n",
      "### Task: You are a test automation script writer. I will describe a UI test in German and you will generate Playwright test code for the given webpage. Strictly follow these instructions: 1. Don't explain the code, just generate the code block itself. 2. You get some HTML elements and its attributes from the website. You can use playwright locators to find the elements by their attributes. 3. Use the precondition code to set up the initial state. You must continue the code. 4. Follow the steps in the ui test description to perform actions on the website. 5. Use the screenshot to understand the context of the test. Assistant:\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Config \n",
    "\n",
    "TODO"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Simplified HTML Content\n",
    "\n",
    "* In Simplified HTML Content we extract relevant information from the HTML file.\n",
    "* We use **BeautifulSoup** to parse and extract information from the HTML file. ➡️ see src.data.html_processor.py"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task\n",
    "\n",
    "For the task description different templates can be selected: \n",
    "* Template_1:\n",
    "  * 1 suppresses that the LLM explains the generated code\n",
    "  * 2 describes to the LLM which elements it receives from the HTML\n",
    "  * 3 causes the LLM to continue the precondition code\n",
    "  * 4 explains to the LLM where it can read the description of the steps to be added\n",
    "  * 5 says that the LLM should also use the screenshot.\n",
    "* Template_2:\n",
    "  *    This template is a predecessor of Template_1 and has no subdivision. It contains most of the points from Template_1.\n",
    "* Template_3 and Template_4:\n",
    "  * The templates are the German translation of Template_1 and Template_2.\n",
    "* Template_5:\n",
    "    * Idea: LLM has always generated too much new code (example)\n",
    "    * Is an extension of Template_1 with the instruction that no more than 3 new lines of code should be added.\n",
    "    * 2 and 4 were slightly modified.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Finetuning\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Training, Validation and Test dataset\n",
    "\n",
    "TODO"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Changes in the Code-Base Llava\n",
    "\n",
    "* The codebase has been adapted in three cases\n",
    "    *\tllava/train/train.py: The DataArguments was adapted to pass an additional validation data set. The make_supervised_data_module method also had to be adapted for this. In addition, the data module is also saved in the train method for debugging.\n",
    "    *\tllava/model/language_model/llava_llama.py: The parameter cache_position=None was added to the forward method in the LlavaLlamaForCausalLM class to fix an error.\n",
    "    *\tllava/eval/run_llava.py: The eval_model method has been adapted to output the input and output to the model for better debugging.\n",
    "* Evaluation runs via the main in model_llava.py\n",
    "    *\tThe main method calls main.py in the cadenza-playwright-llm folder for each sample. The normal pipeline is then executed in this.\n",
    "    *\tFurthermore, the class LLaVAModel is located in the file\n",
    "    *\tThis code is largely taken from the eval_model method from llava/eval/run_llava.py.\n",
    "    *\tA class was created from the method so that the model only has to be loaded once. (For one run)\n",
    "    *\tFurthermore, the method has been rewritten so that no image can be transferred.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Bash-Scripts\n",
    "\n",
    "The job_eval_all_tests.sh bash script which is in the code cell underneath generates tests with the LLM for all entries in the database and stores them in a newly created folder pred_test_script in the cadenza-playwright-llm folder. The script calls the main in llava_model.py. The MODEL_PATH parameter specifies the model used."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --output=/pfs/data5/home/kit/tm/ge6778/PSDA/output/eval/%j.out\n",
    "#SBATCH --error=/pfs/data5/home/kit/tm/ge6778/PSDA/error/eval/%j.err\n",
    "#SBATCH --time=30:00  # Set the time limit to 2 hours\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --partition=sdil\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --cpus-per-task=10\n",
    "\n",
    "export USERNAME=ge6778          # Your username\n",
    "export ENV=llava                # Name of your conda enviroment\n",
    "export PATH_TO_MAIN_FOLDER=PSDA # Folder with data and model\n",
    "export MODEL_PATH=liuhaotian/llava-v1.5-7b\n",
    "#export MODEL_PATH=/pfs/data5/home/kit/tm/${USERNAME}/${PATH_TO_MAIN_FOLDER}/llava-v1.5-7b-finetune_lora-test-template-1-gpu-2_merged\n",
    "export MODEL_PATH=/pfs/data5/home/kit/tm/${USERNAME}/${PATH_TO_MAIN_FOLDER}/llava-v1.5-7b-finetune_lora-test-T5_sc-_html+_single_epoch-5_merged\n",
    "\n",
    "module purge\n",
    "module load devel/cuda/11.7\n",
    "#module load devel/cudnn/10.2\n",
    "module load devel/miniconda/23.9.0-py3.9.15-bwHPC-channel\n",
    "\n",
    "# select and activate our enviroment\n",
    "conda activate ${ENV}\n",
    "\n",
    "# go to llava directory and set pathvariable\n",
    "cd /pfs/data5/home/kit/tm/${USERNAME}/${PATH_TO_MAIN_FOLDER}/cadenza-playwright-llm\n",
    "export PYTHONPATH=/pfs/data5/home/kit/tm/${USERNAME}/${PATH_TO_MAIN_FOLDER}/LLaVA:$PYTHONPATH\n",
    "# enable the automatic boosting of GPU clock speeds\n",
    "nvidia-smi --auto-boost-default=ENABLED\n",
    "\n",
    "\n",
    "export LD_LIBRARY_PATH=/opt/bwhpc/common/toolkit/nvidia_hpc_sdk/23.9/Linux_x86_64/23.9/comm_libs/nccl/lib/:$LD_LIBRARY_PATH\n",
    "export NCCL_DEBUG=INFO\n",
    "export TORCH_NCCL_ASYNC_ERROR_HANDLING=1\n",
    "# export NCCL_BLOCKING_WAIT=1\n",
    "export TORCH_DISTRIBUTED_DEBUG=INFO\n",
    "\n",
    "HEAD_ADDRESS=$(scontrol show hostnames \"$SLURM_JOB_NODELIST\" | head -n 1)\n",
    "# MASTER_IP=$(srun -N1 -w $HEAD_ADDRESS bash -c \"ip -o -4 addr show ib0 | awk '{print \\$4}' | cut -d/ -f1\")\n",
    "MASTER_IP=$(srun -N1 -w $HEAD_ADDRESS bash -c \"ip -o -4 addr show ens3f0 | awk '{print \\$4}' | cut -d/ -f1\")\n",
    "WORLD_SIZE=$(($SLURM_NNODES * $SLURM_NTASKS_PER_NODE))\n",
    "\n",
    "if [ -z \"$MASTER_IP\" ]; then\n",
    "  echo \"No valid IP address found for ib0. Exiting.\"\n",
    "  exit 1\n",
    "fi\n",
    "\n",
    "export HEAD_ADDRESS MASTER_IP WORLD_SIZE\n",
    "\n",
    "\n",
    "NCCL_SOCKET_IFNAME=ens3f0 # will automap to ib for data transfer. \n",
    "# NCCL_SOCKET_IFNAME=ib0\n",
    "export NCCL_SOCKET_IFNAME\n",
    "\n",
    "# check if network is working\n",
    "echo \"Verifying network settings...\"\n",
    "echo \"Worldsize:\"\n",
    "echo $WORLD_SIZE\n",
    "echo \"Slurm nnodes:\"\n",
    "echo $SLURM_NNODES\n",
    "echo \"Slurm nodeid:\"\n",
    "echo $SLURM_NODEID\n",
    "echo \"Hostname:\"\n",
    "srun hostname\n",
    "echo \"All network interfaces on the master node ($HEAD_ADDRESS):\"\n",
    "srun -N1 -w $HEAD_ADDRESS ip a\n",
    "echo \"Using network interface: $NCCL_SOCKET_IFNAME for NCCL communication\"\n",
    "srun ip a show $NCCL_SOCKET_IFNAME\n",
    "echo \"Testing connection to master ip\"\n",
    "srun ping -c 4 $MASTER_IP\n",
    "echo \"Testing connection among nodes\"\n",
    "for node in $(scontrol show hostnames \"$SLURM_JOB_NODELIST\"); do\n",
    "    echo \"Testing connectivity from $node to $MASTER_IP...\"\n",
    "    srun -N1 -w $node ping -c 4 $MASTER_IP\n",
    "done\n",
    "\n",
    "python ../cadenza-playwright-llm/src/models/llm/llava_model.py \\\n",
    "    --model-path ${MODEL_PATH}\n",
    "\n",
    "echo \"Training\"\n",
    "echo \"Finished at: $(date)\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The bash script for finetuning is job_finetune.sh which is in the code cell underneath. In this script, the MODEL_PATH parameter is used to specify the model to be finetuned and the OUTPUT_DIR parameter is used to specify the output folder. \n",
    "   * In addition, a validation data set is also transferred in validation_data_path.\n",
    "   * 2 GPUs are selected, as there is not enough memory with one.\n",
    "   * Important: The parameter “--mm_projector_type mlp2x_gelu” must be added for Deepspeed, otherwise the model cannot be loaded correctly later. Some weights of the model are otherwise initialized randomly and the output of the finetuned model was empty.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --output=/pfs/data5/home/kit/tm/ge6778/PSDA/output/%j.out\n",
    "#SBATCH --error=/pfs/data5/home/kit/tm/ge6778/PSDA/error/%j.err\n",
    "#SBATCH --time=45:00  # Set the time limit to 2 hours\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --partition=sdil\n",
    "#SBATCH --gres=gpu:2\n",
    "#SBATCH --cpus-per-task=10\n",
    "\n",
    "export USERNAME=ge6778          # Your username\n",
    "export ENV=llava                # Name of your conda enviroment\n",
    "export PATH_TO_MAIN_FOLDER=PSDA # Folder with data and model\n",
    "export MODEL_PATH=/pfs/data5/home/kit/tm/ge6778/PSDA/llava-v1.5-7b\n",
    "#export MODEL_PATH=llava-hf/llava-1.5-7b-hf\n",
    "export OUTPUT_DIR=llava-v1.5-7b-finetune_lora-test-T5_sc+_html+_single_epoch-5-REDO\n",
    "\n",
    "module purge\n",
    "module load devel/cuda/11.7\n",
    "#module load devel/cudnn/10.2\n",
    "module load devel/miniconda/23.9.0-py3.9.15-bwHPC-channel\n",
    "\n",
    "# select and activate our enviroment\n",
    "conda activate ${ENV}\n",
    "\n",
    "# go to llava directory and set pathvariable\n",
    "# TODO: Changed variable \n",
    "cd /pfs/data5/home/kit/tm/${USERNAME}/${PATH_TO_MAIN_FOLDER}/LLaVA\n",
    "#cd /pfs/data5/home/kit/tm/${USERNAME}/${PATH_TO_MAIN_FOLDER}/cadenza-playwright-llm/LLaVA\n",
    "export PYTHONPATH=/pfs/data5/home/kit/tm/${USERNAME}/${PATH_TO_MAIN_FOLDER}/LLaVA:$PYTHONPATH\n",
    "# enable the automatic boosting of GPU clock speeds\n",
    "nvidia-smi --auto-boost-default=ENABLED\n",
    "\n",
    "\n",
    "export LD_LIBRARY_PATH=/opt/bwhpc/common/toolkit/nvidia_hpc_sdk/23.9/Linux_x86_64/23.9/comm_libs/nccl/lib/:$LD_LIBRARY_PATH\n",
    "export NCCL_DEBUG=INFO\n",
    "export TORCH_NCCL_ASYNC_ERROR_HANDLING=1\n",
    "# export NCCL_BLOCKING_WAIT=1\n",
    "export TORCH_DISTRIBUTED_DEBUG=INFO\n",
    "\n",
    "HEAD_ADDRESS=$(scontrol show hostnames \"$SLURM_JOB_NODELIST\" | head -n 1)\n",
    "# MASTER_IP=$(srun -N1 -w $HEAD_ADDRESS bash -c \"ip -o -4 addr show ib0 | awk '{print \\$4}' | cut -d/ -f1\")\n",
    "MASTER_IP=$(srun -N1 -w $HEAD_ADDRESS bash -c \"ip -o -4 addr show ens3f0 | awk '{print \\$4}' | cut -d/ -f1\")\n",
    "WORLD_SIZE=$(($SLURM_NNODES * $SLURM_NTASKS_PER_NODE))\n",
    "\n",
    "if [ -z \"$MASTER_IP\" ]; then\n",
    "  echo \"No valid IP address found for ib0. Exiting.\"\n",
    "  exit 1\n",
    "fi\n",
    "\n",
    "export HEAD_ADDRESS MASTER_IP WORLD_SIZE\n",
    "\n",
    "\n",
    "NCCL_SOCKET_IFNAME=ens3f0 # will automap to ib for data transfer. \n",
    "# NCCL_SOCKET_IFNAME=ib0\n",
    "export NCCL_SOCKET_IFNAME\n",
    "\n",
    "# check if network is working\n",
    "echo \"Verifying network settings...\"\n",
    "echo \"Worldsize:\"\n",
    "echo $WORLD_SIZE\n",
    "echo \"Slurm nnodes:\"\n",
    "echo $SLURM_NNODES\n",
    "echo \"Slurm nodeid:\"\n",
    "echo $SLURM_NODEID\n",
    "echo \"Hostname:\"\n",
    "srun hostname\n",
    "echo \"All network interfaces on the master node ($HEAD_ADDRESS):\"\n",
    "srun -N1 -w $HEAD_ADDRESS ip a\n",
    "echo \"Using network interface: $NCCL_SOCKET_IFNAME for NCCL communication\"\n",
    "srun ip a show $NCCL_SOCKET_IFNAME\n",
    "echo \"Testing connection to master ip\"\n",
    "srun ping -c 4 $MASTER_IP\n",
    "echo \"Testing connection among nodes\"\n",
    "for node in $(scontrol show hostnames \"$SLURM_JOB_NODELIST\"); do\n",
    "    echo \"Testing connectivity from $node to $MASTER_IP...\"\n",
    "    srun -N1 -w $node ping -c 4 $MASTER_IP\n",
    "done\n",
    "\n",
    "deepspeed llava/train/train_mem.py \\\n",
    "    --deepspeed ./scripts/zero3.json \\\n",
    "    --lora_enable True --lora_r 128 --lora_alpha 256 --mm_projector_lr 2e-5 \\\n",
    "    --model_name_or_path ${MODEL_PATH}\\\n",
    "    --version v1 \\\n",
    "    --data_path /pfs/data5/home/kit/tm/${USERNAME}/${PATH_TO_MAIN_FOLDER}/data/finetune/s61_finetuning_data_train_finetuned_T5_sc+_html+_single_20240719-194726.json \\\n",
    "    --validation_data_path /pfs/data5/home/kit/tm/${USERNAME}/${PATH_TO_MAIN_FOLDER}/data/finetune/s18_finetuning_data_val_finetuned_T5_sc+_html+_single_20240719-194726.json \\\n",
    "    --image_folder /pfs/data5/home/kit/tm/${USERNAME}/${PATH_TO_MAIN_FOLDER}/cadenza-playwright-llm \\\n",
    "    --vision_tower openai/clip-vit-large-patch14-336 \\\n",
    "    --mm_projector_type mlp2x_gelu \\\n",
    "    --mm_vision_select_layer -2 \\\n",
    "    --mm_use_im_start_end False \\\n",
    "    --mm_use_im_patch_token False \\\n",
    "    --bf16 True \\\n",
    "    --output_dir /pfs/data5/home/kit/tm/${USERNAME}/${PATH_TO_MAIN_FOLDER}/${OUTPUT_DIR} \\\n",
    "    --num_train_epochs 5 \\\n",
    "    --per_device_train_batch_size 8 \\\n",
    "    --per_device_eval_batch_size 4 \\\n",
    "    --gradient_accumulation_steps 1 \\\n",
    "    --evaluation_strategy \"steps\" \\\n",
    "    --save_strategy \"epoch\" \\\n",
    "    --save_total_limit 1 \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --weight_decay 0. \\\n",
    "    --warmup_ratio 0.03 \\\n",
    "    --lr_scheduler_type \"cosine\" \\\n",
    "    --logging_steps 1 \\\n",
    "    --tf32 True \\\n",
    "    --model_max_length 2048 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --lazy_preprocess True \\\n",
    "    --dataloader_num_workers 4 \\\n",
    "    --report_to wandb\n",
    "\n",
    "\n",
    "python scripts/merge_lora_weights.py \\\n",
    "    --model-path /pfs/data5/home/kit/tm/${USERNAME}/${PATH_TO_MAIN_FOLDER}/${OUTPUT_DIR} \\\n",
    "    --model-base ${MODEL_PATH} \\\n",
    "    --save-model-path /pfs/data5/home/kit/tm/${USERNAME}/${PATH_TO_MAIN_FOLDER}/${OUTPUT_DIR}_merged\n",
    "\n",
    "\n",
    "echo \"Training\"\n",
    "echo \"Finished at: $(date)\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loss on Training and Validation dataset"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
